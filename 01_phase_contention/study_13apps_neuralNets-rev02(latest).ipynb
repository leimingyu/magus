{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys # error msg, add the modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import copy\n",
    "\n",
    "sys.path.append(\"../pycode/\")\n",
    "from magus_util import read_nvprof_trace, parse_nvprof_trace, getruntime, sort_dict_by_val, genNNFeat\n",
    "from magus_contention import *\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obtain trace files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binopt_trace.csv', 'sortingNetworks_trace.csv', 'transpose_trace.csv', 'SobolQRNG_trace.csv', 'reduction_trace.csv', 'matrixMul_trace.csv', 'MC_SingleAsianOptionP_trace.csv', 'mergeSort_trace.csv', 'interval_trace.csv', 'quasirandomGenerator_trace.csv', 'convolutionFFT2D_trace.csv', 'radixSortThrust_trace.csv', 'scan_trace.csv']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 13 cuda apps\n",
    "#\n",
    "traceFolder = \"./test_files\"\n",
    "appTraces = os.listdir(traceFolder)\n",
    "print appTraces\n",
    "print len(appTraces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FDTD3d_trace.csv', 'convolutionSeparable_trace.csv', 'dct8x8_trace.csv', 'nvgraph_Pagerank_trace.csv', 'histogram_trace.csv', 'batchCUBLAS_trace.csv', 'simpleCUFFT_callback_trace.csv', 'conjugateGradient_trace.csv', 'boxFilterNPP_trace.csv', 'BlackScholes_trace.csv']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# additional 10 apps \n",
    "#\n",
    "traceFolder_extra = \"./test_apps_trace\"\n",
    "appTraces_extra = os.listdir(traceFolder_extra)\n",
    "print appTraces_extra\n",
    "print len(appTraces_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate feature matrix based on traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 13 cuda apps \n",
      "\n",
      "binopt\n",
      "sortingNetworks\n",
      "transpose\n",
      "SobolQRNG\n",
      "reduction\n",
      "matrixMul\n",
      "MC_SingleAsianOptionP\n",
      "mergeSort\n",
      "interval\n",
      "quasirandomGenerator\n",
      "convolutionFFT2D\n",
      "radixSortThrust\n",
      "scan\n",
      "\n",
      " extra 10 cuda apps \n",
      "\n",
      "FDTD3d\n",
      "convolutionSeparable\n",
      "dct8x8\n",
      "nvgraph_Pagerank\n",
      "histogram\n",
      "batchCUBLAS\n",
      "simpleCUFFT_callback\n",
      "conjugateGradient\n",
      "boxFilterNPP\n",
      "BlackScholes\n"
     ]
    }
   ],
   "source": [
    "app_feat_array = None\n",
    "app_rowid_dict = {}\n",
    "appTraceDict = {}\n",
    "\n",
    "#\n",
    "# 13 cuda apps\n",
    "#\n",
    "print('\\n 13 cuda apps \\n')\n",
    "for i, eachAppTrace in enumerate(appTraces):\n",
    "    appName = eachAppTrace[:-10]\n",
    "    print appName\n",
    "    file_csv = traceFolder + '/' + eachAppTrace \n",
    "    #print file_csv\n",
    "    df_trace = read_nvprof_trace(file_csv)\n",
    "    appTraceList = parse_nvprof_trace(df_trace)\n",
    "    #print appTraceList\n",
    "    appTraceDict[appName] = appTraceList\n",
    "    \n",
    "    if i == 0:\n",
    "        app_feat_array = genNNFeat(appTraceList)\n",
    "    else:\n",
    "        app_feat_array = np.vstack((app_feat_array, genNNFeat(appTraceList)))\n",
    "        \n",
    "    #print i\n",
    "    app_rowid_dict[appName] = i\n",
    "\n",
    "#\n",
    "# additional 10 apps \n",
    "#   \n",
    "print('\\n extra 10 cuda apps \\n')\n",
    "for i, eachAppTrace in enumerate(appTraces_extra):\n",
    "    appName = eachAppTrace[:-10]\n",
    "    print appName\n",
    "    \n",
    "    file_csv = traceFolder_extra + '/' + eachAppTrace \n",
    "    #print file_csv\n",
    "    \n",
    "    df_trace = read_nvprof_trace(file_csv)\n",
    "    appTraceList = parse_nvprof_trace(df_trace)\n",
    "    #print appTraceList\n",
    "    \n",
    "    appTraceDict[appName] = appTraceList\n",
    "    \n",
    "    app_feat_array = np.vstack((app_feat_array, genNNFeat(appTraceList)))\n",
    "     \n",
    "    #print i + 13\n",
    "    app_rowid_dict[appName] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['h2d', 566.138617, 566.141849, 0.0, 0.0, 0.0, 0.0],\n",
       " ['kern', 566.150169, 575.913912, 1024.0, 128.0, 32.0, 516.0],\n",
       " ['d2h', 575.915512, 575.917496, 0.0, 0.0, 0.0, 0.0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appTrace = appTraceDict['binopt']\n",
    "appTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['h2d', 12137.205, 12703.343918, 0.0, 0.0, 0.0, 0.0],\n",
       " ['h2d', 12703.43, 13269.573654, 0.0, 0.0, 0.0, 0.0],\n",
       " ['h2d', 13269.586000000001, 13269.587184000002, 0.0, 0.0, 0.0, 0.0],\n",
       " ['kern', 13269.617999999999, 13272.026054999998, 288.0, 512.0, 40.0, 3750.0],\n",
       " ['kern', 13272.027, 13274.409998, 288.0, 512.0, 40.0, 3750.0],\n",
       " ['kern', 13274.412, 13276.803031, 288.0, 512.0, 40.0, 3750.0],\n",
       " ['kern', 13276.805, 13279.185374, 288.0, 512.0, 40.0, 3750.0],\n",
       " ['kern', 13279.187, 13281.584623, 288.0, 512.0, 40.0, 3750.0],\n",
       " ['d2h', 13281.599999999999, 13823.284344999998, 0.0, 0.0, 0.0, 0.0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appTrace = appTraceDict['FDTD3d']\n",
    "appTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 45)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_feat_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BlackScholes': 9,\n",
       " 'FDTD3d': 0,\n",
       " 'MC_SingleAsianOptionP': 6,\n",
       " 'SobolQRNG': 3,\n",
       " 'batchCUBLAS': 5,\n",
       " 'binopt': 0,\n",
       " 'boxFilterNPP': 8,\n",
       " 'conjugateGradient': 7,\n",
       " 'convolutionFFT2D': 10,\n",
       " 'convolutionSeparable': 1,\n",
       " 'dct8x8': 2,\n",
       " 'histogram': 4,\n",
       " 'interval': 8,\n",
       " 'matrixMul': 5,\n",
       " 'mergeSort': 7,\n",
       " 'nvgraph_Pagerank': 3,\n",
       " 'quasirandomGenerator': 9,\n",
       " 'radixSortThrust': 11,\n",
       " 'reduction': 4,\n",
       " 'scan': 12,\n",
       " 'simpleCUFFT_callback': 6,\n",
       " 'sortingNetworks': 1,\n",
       " 'transpose': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row index in app_feat_array[]\n",
    "app_rowid_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read the ground truth files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'mergeSort', u'reduction', 1]\n",
      "[u'mergeSort', u'SobolQRNG', 0]\n",
      "[u'mergeSort', u'scan', 0]\n",
      "[u'mergeSort', u'matrixMul', 0]\n",
      "[u'mergeSort', u'convfft2d', 1]\n",
      "[u'mergeSort', u'quasirandomGenerator', 1]\n",
      "[u'mergeSort', u'binopt', 1]\n",
      "[u'mergeSort', u'interval', 0]\n",
      "[u'mergeSort', u'MCSingleAsianOptionP', 0]\n",
      "[u'mergeSort', u'transpose', 0]\n",
      "[u'mergeSort', u'radixSortThrust', 1]\n",
      "[u'mergeSort', u'sortingNetworks', 1]\n",
      "[u'radixSortThrust', u'scan', 0]\n",
      "[u'radixSortThrust', u'reduction', 0]\n",
      "[u'radixSortThrust', u'mergeSort', 1]\n",
      "[u'radixSortThrust', u'interval', 1]\n",
      "[u'radixSortThrust', u'matrixMul', 1]\n",
      "[u'radixSortThrust', u'SobolQRNG', 1]\n",
      "[u'radixSortThrust', u'transpose', 1]\n",
      "[u'radixSortThrust', u'sortingNetworks', 1]\n",
      "[u'radixSortThrust', u'binopt', 1]\n",
      "[u'radixSortThrust', u'convfft2d', 1]\n",
      "[u'radixSortThrust', u'quasirandomGenerator', 1]\n",
      "[u'radixSortThrust', u'MCSingleAsianOptionP', 0]\n",
      "[u'scan', u'MCSingleAsianOptionP', 0]\n",
      "[u'scan', u'convfft2d', 1]\n",
      "[u'scan', u'interval', 1]\n",
      "[u'scan', u'reduction', 0]\n",
      "[u'scan', u'radixSortThrust', 0]\n",
      "[u'scan', u'transpose', 0]\n",
      "[u'scan', u'quasirandomGenerator', 1]\n",
      "[u'scan', u'SobolQRNG', 1]\n",
      "[u'scan', u'mergeSort', 0]\n",
      "[u'scan', u'matrixMul', 0]\n",
      "[u'scan', u'binopt', 1]\n",
      "[u'scan', u'sortingNetworks', 1]\n",
      "[u'SobolQRNG', u'mergeSort', 1]\n",
      "[u'SobolQRNG', u'quasirandomGenerator', 0]\n",
      "[u'SobolQRNG', u'matrixMul', 0]\n",
      "[u'SobolQRNG', u'reduction', 1]\n",
      "[u'SobolQRNG', u'interval', 0]\n",
      "[u'SobolQRNG', u'scan', 1]\n",
      "[u'SobolQRNG', u'sortingNetworks', 0]\n",
      "[u'SobolQRNG', u'radixSortThrust', 1]\n",
      "[u'SobolQRNG', u'MCSingleAsianOptionP', 0]\n",
      "[u'SobolQRNG', u'convfft2d', 0]\n",
      "[u'SobolQRNG', u'binopt', 0]\n",
      "[u'SobolQRNG', u'transpose', 0]\n",
      "[u'transpose', u'convfft2d', 0]\n",
      "[u'transpose', u'SobolQRNG', 0]\n",
      "[u'transpose', u'reduction', 1]\n",
      "[u'transpose', u'MCSingleAsianOptionP', 0]\n",
      "[u'transpose', u'interval', 0]\n",
      "[u'transpose', u'binopt', 0]\n",
      "[u'transpose', u'mergeSort', 0]\n",
      "[u'transpose', u'scan', 0]\n",
      "[u'transpose', u'matrixMul', 0]\n",
      "[u'transpose', u'sortingNetworks', 0]\n",
      "[u'transpose', u'radixSortThrust', 1]\n",
      "[u'transpose', u'quasirandomGenerator', 0]\n",
      "[u'interval', u'radixSortThrust', 1]\n",
      "[u'interval', u'convfft2d', 1]\n",
      "[u'interval', u'reduction', 1]\n",
      "[u'interval', u'MCSingleAsianOptionP', 0]\n",
      "[u'interval', u'binopt', 1]\n",
      "[u'interval', u'mergeSort', 0]\n",
      "[u'interval', u'SobolQRNG', 0]\n",
      "[u'interval', u'scan', 1]\n",
      "[u'interval', u'matrixMul', 0]\n",
      "[u'interval', u'quasirandomGenerator', 1]\n",
      "[u'interval', u'sortingNetworks', 1]\n",
      "[u'interval', u'transpose', 0]\n",
      "[u'binopt', u'reduction', 1]\n",
      "[u'binopt', u'radixSortThrust', 1]\n",
      "[u'binopt', u'sortingNetworks', 1]\n",
      "[u'binopt', u'MCSingleAsianOptionP', 0]\n",
      "[u'binopt', u'transpose', 0]\n",
      "[u'binopt', u'interval', 1]\n",
      "[u'binopt', u'convfft2d', 1]\n",
      "[u'binopt', u'scan', 1]\n",
      "[u'binopt', u'matrixMul', 0]\n",
      "[u'binopt', u'quasirandomGenerator', 1]\n",
      "[u'binopt', u'SobolQRNG', 0]\n",
      "[u'binopt', u'mergeSort', 1]\n",
      "[u'matrixMul', u'binopt', 0]\n",
      "[u'matrixMul', u'SobolQRNG', 0]\n",
      "[u'matrixMul', u'radixSortThrust', 1]\n",
      "[u'matrixMul', u'transpose', 0]\n",
      "[u'matrixMul', u'quasirandomGenerator', 0]\n",
      "[u'matrixMul', u'interval', 0]\n",
      "[u'matrixMul', u'sortingNetworks', 0]\n",
      "[u'matrixMul', u'scan', 0]\n",
      "[u'matrixMul', u'reduction', 0]\n",
      "[u'matrixMul', u'MCSingleAsianOptionP', 0]\n",
      "[u'matrixMul', u'convfft2d', 0]\n",
      "[u'matrixMul', u'mergeSort', 0]\n",
      "[u'quasirandomGenerator', u'mergeSort', 1]\n",
      "[u'quasirandomGenerator', u'reduction', 1]\n",
      "[u'quasirandomGenerator', u'sortingNetworks', 1]\n",
      "[u'quasirandomGenerator', u'interval', 1]\n",
      "[u'quasirandomGenerator', u'binopt', 1]\n",
      "[u'quasirandomGenerator', u'scan', 1]\n",
      "[u'quasirandomGenerator', u'transpose', 0]\n",
      "[u'quasirandomGenerator', u'SobolQRNG', 0]\n",
      "[u'quasirandomGenerator', u'convfft2d', 1]\n",
      "[u'quasirandomGenerator', u'matrixMul', 0]\n",
      "[u'quasirandomGenerator', u'radixSortThrust', 1]\n",
      "[u'quasirandomGenerator', u'MCSingleAsianOptionP', 0]\n",
      "[u'reduction', u'scan', 0]\n",
      "[u'reduction', u'matrixMul', 1]\n",
      "[u'reduction', u'binopt', 1]\n",
      "[u'reduction', u'interval', 1]\n",
      "[u'reduction', u'mergeSort', 1]\n",
      "[u'reduction', u'quasirandomGenerator', 1]\n",
      "[u'reduction', u'convfft2d', 1]\n",
      "[u'reduction', u'radixSortThrust', 0]\n",
      "[u'reduction', u'SobolQRNG', 1]\n",
      "[u'reduction', u'sortingNetworks', 1]\n",
      "[u'reduction', u'MCSingleAsianOptionP', 0]\n",
      "[u'reduction', u'transpose', 1]\n",
      "[u'convfft2d', u'interval', 1]\n",
      "[u'convfft2d', u'MCSingleAsianOptionP', 0]\n",
      "[u'convfft2d', u'reduction', 1]\n",
      "[u'convfft2d', u'quasirandomGenerator', 1]\n",
      "[u'convfft2d', u'mergeSort', 1]\n",
      "[u'convfft2d', u'radixSortThrust', 1]\n",
      "[u'convfft2d', u'binopt', 1]\n",
      "[u'convfft2d', u'matrixMul', 0]\n",
      "[u'convfft2d', u'sortingNetworks', 1]\n",
      "[u'convfft2d', u'transpose', 0]\n",
      "[u'convfft2d', u'SobolQRNG', 0]\n",
      "[u'convfft2d', u'scan', 1]\n",
      "[u'MCSingleAsianOptionP', u'transpose', 0]\n",
      "[u'MCSingleAsianOptionP', u'convfft2d', 0]\n",
      "[u'MCSingleAsianOptionP', u'radixSortThrust', 1]\n",
      "[u'MCSingleAsianOptionP', u'binopt', 0]\n",
      "[u'MCSingleAsianOptionP', u'SobolQRNG', 0]\n",
      "[u'MCSingleAsianOptionP', u'scan', 0]\n",
      "[u'MCSingleAsianOptionP', u'quasirandomGenerator', 0]\n",
      "[u'MCSingleAsianOptionP', u'mergeSort', 0]\n",
      "[u'MCSingleAsianOptionP', u'sortingNetworks', 0]\n",
      "[u'MCSingleAsianOptionP', u'matrixMul', 0]\n",
      "[u'MCSingleAsianOptionP', u'interval', 0]\n",
      "[u'MCSingleAsianOptionP', u'reduction', 0]\n",
      "[u'sortingNetworks', u'interval', 1]\n",
      "[u'sortingNetworks', u'radixSortThrust', 1]\n",
      "[u'sortingNetworks', u'mergeSort', 1]\n",
      "[u'sortingNetworks', u'scan', 1]\n",
      "[u'sortingNetworks', u'reduction', 1]\n",
      "[u'sortingNetworks', u'SobolQRNG', 0]\n",
      "[u'sortingNetworks', u'MCSingleAsianOptionP', 0]\n",
      "[u'sortingNetworks', u'quasirandomGenerator', 1]\n",
      "[u'sortingNetworks', u'convfft2d', 1]\n",
      "[u'sortingNetworks', u'binopt', 1]\n",
      "[u'sortingNetworks', u'transpose', 0]\n",
      "[u'sortingNetworks', u'matrixMul', 0]\n",
      "[u'FDTD3d', u'histogram', 1]\n",
      "[u'FDTD3d', u'batchCUBLAS', 1]\n",
      "[u'FDTD3d', u'boxFilterNPP', 1]\n",
      "[u'FDTD3d', u'dct8x8', 1]\n",
      "[u'FDTD3d', u'simpleCUFFTcallback', 1]\n",
      "[u'FDTD3d', u'convolutionSeparable', 1]\n",
      "[u'FDTD3d', u'nvgraphPagerank', 1]\n",
      "[u'FDTD3d', u'conjugateGradient', 1]\n",
      "[u'FDTD3d', u'BlackScholes', 1]\n",
      "[u'BlackScholes', u'FDTD3d', 1]\n",
      "[u'BlackScholes', u'histogram', 1]\n",
      "[u'BlackScholes', u'nvgraphPagerank', 1]\n",
      "[u'BlackScholes', u'boxFilterNPP', 1]\n",
      "[u'BlackScholes', u'convolutionSeparable', 1]\n",
      "[u'BlackScholes', u'dct8x8', 1]\n",
      "[u'BlackScholes', u'simpleCUFFTcallback', 1]\n",
      "[u'BlackScholes', u'conjugateGradient', 1]\n",
      "[u'BlackScholes', u'batchCUBLAS', 1]\n",
      "[u'boxFilterNPP', u'conjugateGradient', 1]\n",
      "[u'boxFilterNPP', u'histogram', 1]\n",
      "[u'boxFilterNPP', u'FDTD3d', 1]\n",
      "[u'boxFilterNPP', u'convolutionSeparable', 1]\n",
      "[u'boxFilterNPP', u'nvgraphPagerank', 1]\n",
      "[u'boxFilterNPP', u'batchCUBLAS', 1]\n",
      "[u'boxFilterNPP', u'dct8x8', 1]\n",
      "[u'boxFilterNPP', u'simpleCUFFTcallback', 1]\n",
      "[u'boxFilterNPP', u'BlackScholes', 1]\n",
      "[u'convolutionSeparable', u'BlackScholes', 1]\n",
      "[u'convolutionSeparable', u'boxFilterNPP', 1]\n",
      "[u'convolutionSeparable', u'nvgraphPagerank', 1]\n",
      "[u'convolutionSeparable', u'conjugateGradient', 1]\n",
      "[u'convolutionSeparable', u'histogram', 1]\n",
      "[u'convolutionSeparable', u'simpleCUFFTcallback', 1]\n",
      "[u'convolutionSeparable', u'dct8x8', 1]\n",
      "[u'convolutionSeparable', u'batchCUBLAS', 1]\n",
      "[u'convolutionSeparable', u'FDTD3d', 1]\n",
      "[u'histogram', u'BlackScholes', 1]\n",
      "[u'histogram', u'nvgraphPagerank', 1]\n",
      "[u'histogram', u'dct8x8', 1]\n",
      "[u'histogram', u'simpleCUFFTcallback', 1]\n",
      "[u'histogram', u'boxFilterNPP', 1]\n",
      "[u'histogram', u'conjugateGradient', 1]\n",
      "[u'histogram', u'FDTD3d', 1]\n",
      "[u'histogram', u'batchCUBLAS', 1]\n",
      "[u'histogram', u'convolutionSeparable', 1]\n",
      "[u'batchCUBLAS', u'FDTD3d', 1]\n",
      "[u'batchCUBLAS', u'boxFilterNPP', 1]\n",
      "[u'batchCUBLAS', u'nvgraphPagerank', 1]\n",
      "[u'batchCUBLAS', u'dct8x8', 1]\n",
      "[u'batchCUBLAS', u'BlackScholes', 1]\n",
      "[u'batchCUBLAS', u'histogram', 1]\n",
      "[u'batchCUBLAS', u'convolutionSeparable', 1]\n",
      "[u'batchCUBLAS', u'conjugateGradient', 1]\n",
      "[u'batchCUBLAS', u'simpleCUFFTcallback', 1]\n",
      "[u'nvgraphPagerank', u'conjugateGradient', 1]\n",
      "[u'nvgraphPagerank', u'FDTD3d', 1]\n",
      "[u'nvgraphPagerank', u'batchCUBLAS', 1]\n",
      "[u'nvgraphPagerank', u'convolutionSeparable', 1]\n",
      "[u'nvgraphPagerank', u'histogram', 1]\n",
      "[u'nvgraphPagerank', u'boxFilterNPP', 1]\n",
      "[u'nvgraphPagerank', u'simpleCUFFTcallback', 1]\n",
      "[u'nvgraphPagerank', u'BlackScholes', 1]\n",
      "[u'nvgraphPagerank', u'dct8x8', 1]\n",
      "[u'conjugateGradient', u'convolutionSeparable', 1]\n",
      "[u'conjugateGradient', u'nvgraphPagerank', 1]\n",
      "[u'conjugateGradient', u'BlackScholes', 1]\n",
      "[u'conjugateGradient', u'boxFilterNPP', 1]\n",
      "[u'conjugateGradient', u'batchCUBLAS', 1]\n",
      "[u'conjugateGradient', u'FDTD3d', 1]\n",
      "[u'conjugateGradient', u'simpleCUFFTcallback', 1]\n",
      "[u'conjugateGradient', u'histogram', 1]\n",
      "[u'conjugateGradient', u'dct8x8', 1]\n",
      "[u'simpleCUFFTcallback', u'histogram', 1]\n",
      "[u'simpleCUFFTcallback', u'FDTD3d', 1]\n",
      "[u'simpleCUFFTcallback', u'conjugateGradient', 1]\n",
      "[u'simpleCUFFTcallback', u'batchCUBLAS', 1]\n",
      "[u'simpleCUFFTcallback', u'boxFilterNPP', 1]\n",
      "[u'simpleCUFFTcallback', u'convolutionSeparable', 1]\n",
      "[u'simpleCUFFTcallback', u'nvgraphPagerank', 1]\n",
      "[u'simpleCUFFTcallback', u'dct8x8', 1]\n",
      "[u'simpleCUFFTcallback', u'BlackScholes', 1]\n",
      "[u'dct8x8', u'simpleCUFFTcallback', 1]\n",
      "[u'dct8x8', u'FDTD3d', 1]\n",
      "[u'dct8x8', u'conjugateGradient', 1]\n",
      "[u'dct8x8', u'batchCUBLAS', 1]\n",
      "[u'dct8x8', u'BlackScholes', 1]\n",
      "[u'dct8x8', u'nvgraphPagerank', 1]\n",
      "[u'dct8x8', u'convolutionSeparable', 1]\n",
      "[u'dct8x8', u'boxFilterNPP', 1]\n",
      "[u'dct8x8', u'histogram', 1]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Measure the performance for the combination of running two applications concurrently the same gpu\n",
    "#\n",
    "import json\n",
    "\n",
    "#\n",
    "# 13 cuda apps\n",
    "#\n",
    "with open('../00_featSel/contention_tests/combo_truth.json') as json_file:  \n",
    "    combo_list = json.load(json_file)\n",
    "    \n",
    "unique_appName = set()\n",
    "for eachCombo in combo_list:\n",
    "    print eachCombo\n",
    "    unique_appName.add(eachCombo[0])\n",
    "\n",
    "#\n",
    "# 10 extra cuda apps\n",
    "#\n",
    "with open('./combo_truth_testApps.json') as json_file:  \n",
    "    combo_list_extra = json.load(json_file)\n",
    "    \n",
    "for eachCombo in combo_list_extra:\n",
    "    print eachCombo\n",
    "    unique_appName.add(eachCombo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxFilterNPP\n",
      "scan\n",
      "[Warning] convolutionFFT2D is not in the same app name.\n",
      "convolutionSeparable\n",
      "mergeSort\n",
      "[Warning] MC_SingleAsianOptionP is not in the same app name.\n",
      "SobolQRNG\n",
      "matrixMul\n",
      "BlackScholes\n",
      "reduction\n",
      "binopt\n",
      "sortingNetworks\n",
      "FDTD3d\n",
      "[Warning] simpleCUFFT_callback is not in the same app name.\n",
      "transpose\n",
      "histogram\n",
      "quasirandomGenerator\n",
      "conjugateGradient\n",
      "dct8x8\n",
      "[Warning] nvgraph_Pagerank is not in the same app name.\n",
      "batchCUBLAS\n",
      "interval\n",
      "radixSortThrust\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# print out unique apps\n",
    "#\n",
    "for key, value in app_rowid_dict.iteritems():\n",
    "    if key in unique_appName:\n",
    "        print key\n",
    "    else:\n",
    "        print(\"[Warning] {} is not in the same app name.\".format(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### buid the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = None\n",
    "y_label = np.zeros(len(combo_list) + len(combo_list_extra), dtype=np.int32)\n",
    "\n",
    "#\n",
    "# 13 cuda apps\n",
    "#\n",
    "count = 0\n",
    "for eachCombo in combo_list:\n",
    "    [app1, app2, goodCombo]= eachCombo\n",
    "    #print app1, app2, goodCombo\n",
    "    \n",
    "    if app1 == \"MCSingleAsianOptionP\": app1 = \"MC_SingleAsianOptionP\"\n",
    "    if app1 == \"convfft2d\":            app1 = \"convolutionFFT2D\"\n",
    "    \n",
    "    if app2 == \"MCSingleAsianOptionP\": app2 = \"MC_SingleAsianOptionP\"\n",
    "    if app2 == \"convfft2d\":            app2 = \"convolutionFFT2D\"\n",
    "        \n",
    "    row1 = app_rowid_dict[app1]\n",
    "    row2 = app_rowid_dict[app2]\n",
    "    \n",
    "    arr1 = app_feat_array[row1] # read feature vector for the app\n",
    "    arr2 = app_feat_array[row2]\n",
    "\n",
    "    currentCombo = np.append(arr1, arr2)\n",
    "    \n",
    "    if count == 0:\n",
    "        X_input = currentCombo\n",
    "    else:\n",
    "        X_input = np.vstack((X_input, currentCombo))\n",
    "        \n",
    "    y_label[count] = int(goodCombo)\n",
    "    \n",
    "    count = count + 1\n",
    "\n",
    "\n",
    "#\n",
    "# extra 10 apps\n",
    "#\n",
    "for eachCombo in combo_list_extra:\n",
    "    [app1, app2, goodCombo]= eachCombo\n",
    "    #print app1, app2, goodCombo\n",
    "    \n",
    "    if app1 == \"nvgraphPagerank\":                app1 = \"nvgraph_Pagerank\"\n",
    "    if app1 == \"simpleCUFFTcallback\":            app1 = \"simpleCUFFT_callback\"\n",
    "    \n",
    "    if app2 == \"nvgraphPagerank\":                app2 = \"nvgraph_Pagerank\"\n",
    "    if app2 == \"simpleCUFFTcallback\":            app2 = \"simpleCUFFT_callback\"\n",
    "        \n",
    "    row1 = app_rowid_dict[app1]\n",
    "    row2 = app_rowid_dict[app2]\n",
    "    \n",
    "    arr1 = app_feat_array[row1]\n",
    "    arr2 = app_feat_array[row2]\n",
    "\n",
    "    currentCombo = np.append(arr1, arr2)\n",
    "    \n",
    "    X_input = np.vstack((X_input, currentCombo))\n",
    "        \n",
    "    y_label[count] = int(goodCombo)\n",
    "    \n",
    "    count = count + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check X_input and y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246, 90)\n",
      "(246,)\n"
     ]
    }
   ],
   "source": [
    "print X_input.shape\n",
    "print y_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print combo_list[0]\n",
    "# print y_label[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246, 90)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                                              \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "n_inputs = 90\n",
    "n_hidden = 500    # tunning the layer size here!!!\n",
    "n_outputs = 2    # good (1) or bad (0)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "batch_norm_momentum = 0.9\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    \n",
    "    # avoid repeating the same parameters over and over again\n",
    "    my_batch_norm_layer = partial(tf.layers.batch_normalization,\n",
    "            training=training, momentum=batch_norm_momentum)\n",
    "    \n",
    "    my_dense_layer = partial(tf.layers.dense, kernel_initializer=he_init) # activeFunc after BN\n",
    "    \n",
    "    hidden1 = my_dense_layer(X, n_hidden, name=\"hidden1\")\n",
    "    bn1= my_batch_norm_layer(hidden1)\n",
    "    bn1_act = tf.nn.elu(bn1)\n",
    "    \n",
    "    hidden2 = my_dense_layer(bn1_act, n_hidden, name=\"hidden2\")\n",
    "    bn2 = my_batch_norm_layer(hidden2)\n",
    "    bn2_act = tf.nn.elu(bn2)\n",
    "    \n",
    "    hidden3 = my_dense_layer(bn2_act, n_hidden, name=\"hidden3\")\n",
    "    bn3 = my_batch_norm_layer(hidden3)\n",
    "    bn3_act = tf.nn.elu(bn3)\n",
    "\n",
    "    hidden4 = my_dense_layer(bn3_act, n_hidden, name=\"hidden4\")\n",
    "    bn4_act = tf.nn.elu(my_batch_norm_layer(hidden4))\n",
    "    \n",
    "    hidden5 = my_dense_layer(bn4_act, n_hidden, name=\"hidden5\")\n",
    "    bn5_act = tf.nn.elu(my_batch_norm_layer(hidden5))\n",
    "    \n",
    "    hidden6 = my_dense_layer(bn5_act, n_hidden, name=\"hidden6\")\n",
    "    bn6_act = tf.nn.elu(my_batch_norm_layer(hidden6))\n",
    "    \n",
    "    hidden7 = my_dense_layer(bn6_act, n_hidden, name=\"hidden7\")\n",
    "    bn7_act = tf.nn.elu(my_batch_norm_layer(hidden7))\n",
    "    \n",
    "    hidden8 = my_dense_layer(bn7_act, n_hidden, name=\"hidden8\")\n",
    "    bn8_act = tf.nn.elu(my_batch_norm_layer(hidden8))\n",
    "    \n",
    "    hidden9 = my_dense_layer(bn8_act, n_hidden, name=\"hidden9\")\n",
    "    bn9_act = tf.nn.elu(my_batch_norm_layer(hidden9))\n",
    "    \n",
    "    hidden10 = my_dense_layer(bn9_act, n_hidden, name=\"hidden10\")\n",
    "    bn10_act = tf.nn.elu(my_batch_norm_layer(hidden10))\n",
    "    \n",
    "    # add extra 10 layer\n",
    "    hidden11 = my_dense_layer(bn10_act, n_hidden, name=\"hidden11\")\n",
    "    bn11_act = tf.nn.elu(my_batch_norm_layer(hidden11))\n",
    "    \n",
    "    hidden12 = my_dense_layer(bn11_act, n_hidden, name=\"hidden12\")\n",
    "    bn12_act = tf.nn.elu(my_batch_norm_layer(hidden12))\n",
    "    \n",
    "    hidden13 = my_dense_layer(bn12_act, n_hidden, name=\"hidden13\")\n",
    "    bn13_act = tf.nn.elu(my_batch_norm_layer(hidden13))\n",
    "    \n",
    "    hidden14 = my_dense_layer(bn13_act, n_hidden, name=\"hidden14\")\n",
    "    bn14_act = tf.nn.elu(my_batch_norm_layer(hidden14))\n",
    "    \n",
    "    hidden15 = my_dense_layer(bn14_act, n_hidden, name=\"hidden15\")\n",
    "    bn15_act = tf.nn.elu(my_batch_norm_layer(hidden15))\n",
    "    \n",
    "    hidden16 = my_dense_layer(bn15_act, n_hidden, name=\"hidden16\")\n",
    "    bn16_act = tf.nn.elu(my_batch_norm_layer(hidden16))\n",
    "    \n",
    "    hidden17 = my_dense_layer(bn16_act, n_hidden, name=\"hidden17\")\n",
    "    bn17_act = tf.nn.elu(my_batch_norm_layer(hidden17))\n",
    "    \n",
    "    hidden18 = my_dense_layer(bn17_act, n_hidden, name=\"hidden18\")\n",
    "    bn18_act = tf.nn.elu(my_batch_norm_layer(hidden18))\n",
    "    \n",
    "    hidden19 = my_dense_layer(bn18_act, n_hidden, name=\"hidden19\")\n",
    "    bn19_act = tf.nn.elu(my_batch_norm_layer(hidden19))\n",
    "    \n",
    "    hidden20 = my_dense_layer(bn19_act, n_hidden, name=\"hidden20\")\n",
    "    bn20_act = tf.nn.elu(my_batch_norm_layer(hidden20))\n",
    "    \n",
    "    \n",
    "    # add extra 10 layer\n",
    "    hidden21 = my_dense_layer(bn20_act, n_hidden, name=\"hidden21\")\n",
    "    bn21_act = tf.nn.elu(my_batch_norm_layer(hidden21))\n",
    "    \n",
    "    hidden22 = my_dense_layer(bn21_act, n_hidden, name=\"hidden22\")\n",
    "    bn22_act = tf.nn.elu(my_batch_norm_layer(hidden22))\n",
    "    \n",
    "    hidden23 = my_dense_layer(bn22_act, n_hidden, name=\"hidden23\")\n",
    "    bn23_act = tf.nn.elu(my_batch_norm_layer(hidden23))\n",
    "    \n",
    "    hidden24 = my_dense_layer(bn23_act, n_hidden, name=\"hidden24\")\n",
    "    bn24_act = tf.nn.elu(my_batch_norm_layer(hidden24))\n",
    "    \n",
    "    hidden25 = my_dense_layer(bn24_act, n_hidden, name=\"hidden25\")\n",
    "    bn25_act = tf.nn.elu(my_batch_norm_layer(hidden25))\n",
    "    \n",
    "    hidden26 = my_dense_layer(bn25_act, n_hidden, name=\"hidden26\")\n",
    "    bn26_act = tf.nn.elu(my_batch_norm_layer(hidden26))\n",
    "    \n",
    "    hidden27 = my_dense_layer(bn26_act, n_hidden, name=\"hidden27\")\n",
    "    bn27_act = tf.nn.elu(my_batch_norm_layer(hidden27))\n",
    "    \n",
    "    hidden28 = my_dense_layer(bn27_act, n_hidden, name=\"hidden28\")\n",
    "    bn28_act = tf.nn.elu(my_batch_norm_layer(hidden28))\n",
    "    \n",
    "    hidden29 = my_dense_layer(bn28_act, n_hidden, name=\"hidden29\")\n",
    "    bn29_act = tf.nn.elu(my_batch_norm_layer(hidden29))\n",
    "    \n",
    "    hidden30 = my_dense_layer(bn29_act, n_hidden, name=\"hidden30\")\n",
    "    bn30_act = tf.nn.elu(my_batch_norm_layer(hidden30))\n",
    "    \n",
    "    logits_before_bn = my_dense_layer(bn30_act, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_samples = 246 , n_batches = 2\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 96\n",
    "\n",
    "total_samples = X_input.shape[0]\n",
    "n_batches = int(np.ceil(total_samples / batch_size))\n",
    "print 'total_samples = %d , n_batches = %d' % (total_samples, n_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 0 0 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0\n",
      " 0 1 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "def next_batch(X_input, y_label, batch_size):\n",
    "    samples = X_input.shape[0]\n",
    "    idx = np.arange(0 , samples)\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:batch_size]\n",
    "    \n",
    "    input_shuffle = [X_input[i,:] for i in idx]\n",
    "    label_shuffle = [y_label[i] for i in idx]\n",
    "    \n",
    "    return np.asarray(input_shuffle), np.asarray(label_shuffle)\n",
    "    \n",
    "### test\n",
    "X_batch, y_batch = next_batch(X_input, y_label, batch_size)\n",
    "print y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# log for tensorboard\n",
    "#\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(96, 90), b.shape=(90, 500), m=96, n=500, k=90\n\t [[Node: dnn/hidden1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_X_0_0/_1, hidden1/kernel/read)]]\n\t [[Node: loss/loss/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1495_loss/loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op u'dnn/hidden1/MatMul', defined at:\n  File \"/home/leiming/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/leiming/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-42e22a20bde1>\", line 24, in <module>\n    hidden1 = my_dense_layer(X, n_hidden, name=\"hidden1\")\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/core.py\", line 250, in dense\n    return layer.apply(inputs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 671, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/core.py\", line 162, in call\n    outputs = standard_ops.matmul(inputs, self.kernel)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1891, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2437, in _mat_mul\n    name=name)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(96, 90), b.shape=(90, 500), m=96, n=500, k=90\n\t [[Node: dnn/hidden1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_X_0_0/_1, hidden1/kernel/read)]]\n\t [[Node: loss/loss/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1495_loss/loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-60acc026cc54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# 2) save the loss (at the 5th batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0msummary_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save the loss func values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mfile_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \"\"\"\n\u001b[0;32m--> 570\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_dup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4453\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4454\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4455\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(96, 90), b.shape=(90, 500), m=96, n=500, k=90\n\t [[Node: dnn/hidden1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_X_0_0/_1, hidden1/kernel/read)]]\n\t [[Node: loss/loss/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1495_loss/loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op u'dnn/hidden1/MatMul', defined at:\n  File \"/home/leiming/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/leiming/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-42e22a20bde1>\", line 24, in <module>\n    hidden1 = my_dense_layer(X, n_hidden, name=\"hidden1\")\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/core.py\", line 250, in dense\n    return layer.apply(inputs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 671, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/core.py\", line 162, in call\n    outputs = standard_ops.matmul(inputs, self.kernel)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1891, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2437, in _mat_mul\n    name=name)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/leiming/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(96, 90), b.shape=(90, 500), m=96, n=500, k=90\n\t [[Node: dnn/hidden1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_X_0_0/_1, hidden1/kernel/read)]]\n\t [[Node: loss/loss/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1495_loss/loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "BestAcc = 0.0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(n_batches): # go through all the batches\n",
    "            # 1)  generate batch\n",
    "            X_batch, y_batch = next_batch(X_input, y_label, batch_size)\n",
    "            \n",
    "            # 2) save the loss (at the 5th batch)\n",
    "            if iteration % 2 == 0:\n",
    "                summary_str = loss_summary.eval(feed_dict={X: X_batch, y: y_batch})  # save the loss func values\n",
    "                step = epoch * n_batches + iteration\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "                \n",
    "            # 3) run the training\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "            \n",
    "            \n",
    "        # check the accuracy every 5 epoches\n",
    "        if epoch % 5 == 0:\n",
    "            acc_train = accuracy.eval(feed_dict={X: X_batch,\n",
    "                                                 y: y_batch})\n",
    "            print(epoch, \"Batch accuracy:\", acc_train)\n",
    "            \n",
    "            if acc_train > BestAcc:\n",
    "                BestAcc = acc_train\n",
    "                \n",
    "            if acc_train > 0.92:\n",
    "                # save the model\n",
    "                print('=> Found a good model at accuracy : {}   (Saving the model ... )'.format(acc_train))\n",
    "                save_path = saver.save(sess, \"./dinn_final.ckpt\")\n",
    "\n",
    "                \n",
    "print(\"Best Accuracy Achieved : {}\".format(BestAcc))\n",
    "\n",
    "#\n",
    "# end logging\n",
    "# \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./dinn_final.ckpt\")\n",
    "    logits_pred, correct_pred = sess.run([logits, correct], feed_dict={X: X_input, y: y_label})\n",
    "    print logits_pred[0]\n",
    "    print y_label[0]\n",
    "    print correct_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = X_input[0,:]\n",
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # b = np.transpose(a)\n",
    "# b = a.T\n",
    "# b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = np.reshape(a, (1,90))\n",
    "# b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     saver.restore(sess, \"./model_final_30hdly_500lysize_bah128.ckpt\")\n",
    "#     logits_pred = sess.run([logits, correct], feed_dict={X: b, y: y_label[0]})\n",
    "#     print logits_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
