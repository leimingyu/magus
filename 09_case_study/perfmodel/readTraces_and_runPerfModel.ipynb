{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys # error msg, add the modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import copy\n",
    "\n",
    "sys.path.append(\"../../pycode/\")\n",
    "from magus_util import read_nvprof_trace, parse_nvprof_trace, getruntime, sort_dict_by_val\n",
    "from magus_contention import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# read metrics for sim\n",
    "#\n",
    "app2metric_dd = np.load('../similarity/app2metric_dd.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(app2metric_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "#read traces files in similarity folder\n",
    "#\n",
    "\n",
    "traceFolder = \"../similarity/traces/\"\n",
    "\n",
    "traceFiles = os.listdir(traceFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['traces_cudasdk_MCEstimatePiP.csv',\n",
       " 'traces_cudasdk_simpleCUBLAS.csv',\n",
       " 'traces_cudasdk_shflscan.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traceFiles[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print len(traceFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse traces and save them into data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudasdk_MCEstimatePiP\n",
      "cudasdk_simpleCUBLAS\n",
      "cudasdk_shflscan\n",
      "poly_gesummv\n",
      "cudasdk_binomialOptions\n",
      "poly_atax\n",
      "cudasdk_lineOfSight\n",
      "lonestar_mst\n",
      "cudasdk_BlackScholes\n",
      "cudasdk_MCSingleAsianOptionP\n",
      "shoc_lev1sort\n",
      "poly_3dconv\n",
      "rodinia_hotspot\n",
      "cudasdk_scalarProd\n",
      "poly_3mm\n",
      "parboil_mriq\n",
      "parboil_stencil\n",
      "poly_gemm\n",
      "cudasdk_radixSortThrust\n",
      "rodinia_gaussian\n",
      "cudasdk_SobolQRNG\n",
      "poly_fdtd2d\n",
      "rodinia_pathfinder\n",
      "poly_correlation\n",
      "shoc_lev1BFS\n",
      "cudasdk_convolutionTexture\n",
      "lonestar_sssp\n",
      "shoc_lev1reduction\n",
      "cudasdk_concurrentKernels\n",
      "rodinia_lud\n",
      "shoc_lev1fft\n",
      "cudasdk_MCEstimatePiQ\n",
      "cudasdk_batchCUBLAS\n",
      "shoc_lev1GEMM\n",
      "poly_syrk\n",
      "cudasdk_matrixMul\n",
      "cudasdk_convolutionFFT2D\n",
      "cudasdk_dxtc\n",
      "rodinia_hybridsort\n",
      "cudasdk_c++11Cuda\n",
      "rodinia_needle\n",
      "cudasdk_stereoDisparity\n",
      "poly_mvt\n",
      "cudasdk_threadFenceReduction\n",
      "lonestar_bh\n",
      "cudasdk_mergeSort\n",
      "parboil_lbm\n",
      "rodinia_dwt2d\n",
      "rodinia_backprop\n",
      "parboil_sgemm\n",
      "cudasdk_convolutionSeparable\n",
      "cudasdk_boxFilterNPP\n",
      "cudasdk_scan\n",
      "cudasdk_dwtHaar1D\n",
      "cudasdk_quasirandomGenerator\n",
      "cudasdk_interval\n",
      "cudasdk_vectorAdd\n",
      "cudasdk_eigenvalues\n",
      "cudasdk_transpose\n",
      "rodinia_lavaMD\n",
      "rodinia_heartwall\n",
      "poly_covariance\n",
      "lonestar_dmr\n",
      "poly_syr2k\n",
      "cudasdk_dct8x8\n",
      "cudasdk_MCEstimatePiInlineQ\n",
      "parboil_cutcp\n",
      "cudasdk_simpleCUFFTcallback\n",
      "rodinia_b+tree\n",
      "cudasdk_FDTD3d\n",
      "poly_bicg\n",
      "shoc_lev1md5hash\n",
      "cudasdk_segmentationTreeThrust\n",
      "poly_2dconv\n",
      "cudasdk_MCEstimatePiInlineP\n",
      "cudasdk_reduction\n",
      "cudasdk_sortingNetworks\n",
      "parboil_bfs\n",
      "cudasdk_fastWalshTransform\n"
     ]
    }
   ],
   "source": [
    "app2trace_dd = {}\n",
    "\n",
    "for appcsv in traceFiles:\n",
    "    #print appcsv[7:][:-4]\n",
    "    \n",
    "    appName = appcsv[7:][:-4]\n",
    "    print appName\n",
    "    \n",
    "    file_csv = traceFolder + appcsv\n",
    "    #print file_csv\n",
    "    \n",
    "    # read csv file to dataframe\n",
    "    df_trace = read_nvprof_trace(file_csv)\n",
    "    \n",
    "    # convert dataframe to trace list\n",
    "    appTraceList = parse_nvprof_trace(df_trace)\n",
    "    \n",
    "    app2trace_dd[appName] = appTraceList\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# save to a file\n",
    "#\n",
    "np.save('app2trace_dd.npy', app2trace_dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run performance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getruntime(appTraceList):\n",
    "    \"\"\"\n",
    "    Return the difference between 1st api start and last api end.\n",
    "    \"\"\"\n",
    "    return appTraceList[-1][2] - appTraceList[0][1]\n",
    "\n",
    "\n",
    "def update_trace_offset(tracelist, offset):\n",
    "    \"\"\"\n",
    "    Adjust the starting time (add offset) to each api call in the traceList.\n",
    "    \"\"\"\n",
    "    for eachApi in tracelist:\n",
    "        eachApi[1] += offset\n",
    "        eachApi[2] += offset\n",
    "        \n",
    "def update_trace_api(tracelist, api_index, offset):\n",
    "    \"\"\"\n",
    "    Adjust the starting time (starting from api_index) in the traceList.\n",
    "    \"\"\"\n",
    "    for pid in xrange(len(tracelist)):\n",
    "        if pid >= api_index:\n",
    "            tracelist[pid][1] += offset\n",
    "            tracelist[pid][2] += offset\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "def adjust_prevTraceTable_api(traceTable, apiID, newStart, oldStart):\n",
    "    offset = newStart - oldStart\n",
    "    for api_id, apiCall in enumerate(traceTable):\n",
    "        # for each api that start before oldStart, remain the same\n",
    "        # that start after oldStart, add an offset\n",
    "        myStart, myEnd = apiCall[1], apiCall[2]\n",
    "        if myStart >= oldStart:\n",
    "            # add offset\n",
    "            traceTable[api_id][1] += offset\n",
    "            traceTable[api_id][2] += offset\n",
    "\n",
    "            \n",
    "\n",
    "def model_contention(prevTraceList, newapi, copyEngineNum=2):\n",
    "    \"\"\"\n",
    "    For the newapi, look for contention duing apiStart and apiEnd.\n",
    "    Default configuration assumes the copy engine number is 2.\n",
    "    \"\"\"\n",
    "    curType, curStart, curEnd = newapi[0], newapi[1], newapi[2]\n",
    "\n",
    "    #print \"\\n(Current Api)\"\n",
    "    #print curType, curStart, curEnd\n",
    "\n",
    "    contentionCount = 0\n",
    "    adjCurrent, adjTraceTab = False, False\n",
    "\n",
    "    # iterate all the apps in the traceTable\n",
    "    for apiID, apiCall in enumerate(prevTraceList):\n",
    "        preType, preStart, preEnd = apiCall[0], apiCall[1], apiCall[2]\n",
    "\n",
    "        if (curStart < preEnd <= curEnd) or (curStart <= preStart < curEnd) or (curStart > preStart and curEnd < preEnd):\n",
    "            if preType == curType:\n",
    "                contentionCount = contentionCount + 1\n",
    "                if preStart <= curStart:  # delay current api till the end of prevEnd\n",
    "                    # print \"adjust new api\"\n",
    "                    adjCurrent = True\n",
    "                    newStart = preEnd\n",
    "                    oldStart = curStart\n",
    "                else:  # move the app in traceTable after current api\n",
    "                    # print \"adjust app in traceTable\"\n",
    "                    adjTraceTab = True\n",
    "                    newStart = curEnd\n",
    "                    oldStart = preStart\n",
    "                # find out whether current api has any contention with previous application's api calls \n",
    "                return contentionCount, adjCurrent, adjTraceTab, newStart, oldStart, apiID\n",
    "\n",
    "\n",
    "            if ((preType == 'h2d' and curType == 'd2h') or (preType == 'd2h' and curType == 'h2d')) and (copyEngineNum == 1):\n",
    "                contentionCount = contentionCount + 1\n",
    "                # Duplicate previous operations\n",
    "                if preStart <= curStart:  # delay current api till the end of prevEnd\n",
    "                    #print \"adjust new api\"\n",
    "                    adjCurrent = True\n",
    "                    newStart = prevEnd\n",
    "                    oldStart = curStart\n",
    "                else:  # move the app in traceTable after current api\n",
    "                    #print \"adjust app in traceTable\"\n",
    "                    adjTraceTab = True\n",
    "                    newStart = curEnd\n",
    "                    oldStart = preStart\n",
    "                return contentionCount, adjCurrent, adjTraceTab, newStart, oldStart, apiID\n",
    "\n",
    "    return contentionCount, adjCurrent, adjTraceTab, None, None, None\n",
    "\n",
    "\n",
    "\n",
    "def predict_perf(prev_trace_org, current_trace_org):\n",
    "    \"\"\"\n",
    "    Predict performance impact between two application traces\n",
    "    \"\"\"\n",
    "    prev_trace = copy.deepcopy(prev_trace_org)\n",
    "    current_trace = copy.deepcopy(current_trace_org)\n",
    "\n",
    "    AvgSlowDown = 0\n",
    "\n",
    "    #===============#\n",
    "    # record the orginal runtime \n",
    "    #===============#\n",
    "    orgTime = []\n",
    "    prev_rt = getruntime(prev_trace)\n",
    "    orgTime.append(prev_rt)\n",
    "    ##print \"\\n=> prev app runtime : %f\" % prev_rt\n",
    "\n",
    "    current_rt = getruntime(current_trace)\n",
    "    ##print \"=> current app runtime : %f\" % current_rt\n",
    "    orgTime.append(current_rt)\n",
    "\n",
    "    #===============#\n",
    "    # figure out when to start the coming workload\n",
    "    #===============#\n",
    "    # get the ending time of 1st api (for prev app) : [apitype, start, end, .... ]\n",
    "    prevapp_type  = prev_trace[0][0]\n",
    "    prevapp_start = prev_trace[0][1]\n",
    "    prevapp_end   = prev_trace[0][2]\n",
    "\n",
    "    newapp_type = current_trace[0][0]\n",
    "\n",
    "    simulate_startPos = None\n",
    "    extra_delay_for_newapp = 0.\n",
    "\n",
    "    if prevapp_type == newapp_type:\n",
    "        # when there is contention, start after prev ends\n",
    "        simulate_startPos = prevapp_end\n",
    "        # [Note] count in the starting delay\n",
    "        extra_delay_for_newapp = prevapp_end - prevapp_start\n",
    "    else:\n",
    "        # if different, assume they start at the same time\n",
    "        simulate_startPos = prevapp_start\n",
    "\n",
    "    newapp_start = current_trace[0][1] # update new app api starting point\n",
    "\n",
    "    prev_cur_diff = simulate_startPos - newapp_start  # the amount to adjust the starting point\n",
    "\n",
    "    newapp_trace = copy.deepcopy(current_trace)\n",
    "\n",
    "    # sync newapp timing with traceTable\n",
    "    update_trace_offset(newapp_trace, prev_cur_diff)\n",
    "\n",
    "    #===============#\n",
    "    # analyze the contention for each API \n",
    "    #===============#\n",
    "    for i in xrange(len(newapp_trace)):\n",
    "        api = newapp_trace[i]\n",
    "        CheckContention = True\n",
    "\n",
    "        while CheckContention:\n",
    "            #\n",
    "            # check contention for current api call\n",
    "            #\n",
    "            contentionCount, adjCurrent, adjTraceTab, newStart, oldStart, apiID = model_contention(prev_trace, api)\n",
    "\n",
    "            if contentionCount == 0:\n",
    "                CheckContention = False  # move to the next api\n",
    "            else:\n",
    "                # there are contention for current api\n",
    "                #print contentionCount, adjCurrent, adjTraceTab, newStart, appID, apiID\n",
    "\n",
    "                if adjCurrent:\n",
    "                    #print \"=>adjust current api\"\n",
    "                    #print \"before updating api\"\n",
    "                    #print newapp_trace\n",
    "\n",
    "                    api_offset = newStart - api[1]\n",
    "                    update_trace_api(newapp_trace, i, api_offset)  # update new app trace list\n",
    "\n",
    "                    #print \"after updating api\"\n",
    "                    #print newapp_trace\n",
    "\n",
    "                if adjTraceTab:\n",
    "                    adjust_prevTraceTable_api(prev_trace, apiID, newStart, oldStart)\n",
    "\n",
    "    #=====================================================#\n",
    "    # measure slowdown ratio for each application\n",
    "    #=====================================================#\n",
    "    newTime = []\n",
    "    myRuntime = getruntime(prev_trace)\n",
    "    ##print \"\\n=> prev app runtime (after adjustment) : %f\" % myRuntime \n",
    "    newTime.append(myRuntime)\n",
    "\n",
    "    # add adjusted timing for new app + with extra starting delay\n",
    "    newTime.append(getruntime(newapp_trace) + extra_delay_for_newapp) \n",
    "    ##print \"\\n=> current app runtime (after adjustment) : %f\" % getruntime(newapp_trace)\n",
    "    \n",
    "    #=====================================================#\n",
    "    # measure slowdown ratio for each application\n",
    "    #=====================================================#\n",
    "    slowdown_ratio = []\n",
    "    for i, newT in enumerate(newTime):\n",
    "        sdr = float(newT) / orgTime[i] - 1.   # compute slowdown ratio\n",
    "        slowdown_ratio.append(sdr)\n",
    "\n",
    "    AvgSlowDown = sum(slowdown_ratio) / float(len(newTime))\n",
    "\n",
    "    return AvgSlowDown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top3_least_slowdown(prev_app_trace, app, app2trace_dd):\n",
    "    AvgSlowDown_dd = {}\n",
    "    for key, value in app2trace_dd.iteritems():\n",
    "        if key <> app:\n",
    "            AvgSlowDown = predict_perf(prev_app_trace, value) # select app to corun\n",
    "            AvgSlowDown_dd[key] = AvgSlowDown\n",
    "            #print AvgSlowDown\n",
    "    avg_slowdown_sort = sorted(AvgSlowDown_dd.items(), key=operator.itemgetter(1))\n",
    "    #print avg_slowdown_sort\n",
    "    \n",
    "    print \"\\nTop3 least impact (slowdown) for %s\\n\" % app\n",
    "    print avg_slowdown_sort[0]\n",
    "    print avg_slowdown_sort[1]\n",
    "    print avg_slowdown_sort[2]\n",
    "    \n",
    "#     print \"\\nTop5 least impact (slowdown) for %s\\n\" % app\n",
    "#     print avg_slowdown_sort[0]\n",
    "#     print avg_slowdown_sort[1]\n",
    "#     print avg_slowdown_sort[2]\n",
    "#     print avg_slowdown_sort[3]\n",
    "#     print avg_slowdown_sort[4]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top3 least impact (slowdown) for cudasdk_convolutionSeparable\n",
      "\n",
      "('cudasdk_MCEstimatePiInlineP', 0.0)\n",
      "('cudasdk_concurrentKernels', 0.0)\n",
      "('cudasdk_MCEstimatePiP', 0.0)\n",
      "\n",
      "Top3 least impact (slowdown) for cudasdk_fastWalshTransform\n",
      "\n",
      "('cudasdk_MCEstimatePiInlineQ', 0.0)\n",
      "('cudasdk_MCEstimatePiInlineP', 0.0)\n",
      "('rodinia_gaussian', 0.0)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 2gpus\n",
    "#\n",
    "test1 = ['cudasdk_convolutionSeparable','cudasdk_fastWalshTransform']\n",
    "\n",
    "for app in test1:\n",
    "    select_top3_least_slowdown(app2trace_dd[app],app,app2trace_dd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # apply similarity to select the best\n",
    "\n",
    "\n",
    "# app1_metric = app2metric_dd['cudasdk_convolutionSeparable']\n",
    "\n",
    "# dist_dd = {}\n",
    "# for app2 in ['cudasdk_MCEstimatePiInlineP', 'cudasdk_concurrentKernels', 'cudasdk_MCEstimatePiP']:\n",
    "#     app2_metric = app2metric_dd[app2]\n",
    "#     dist = np.linalg.norm(app1_metric - app2_metric)\n",
    "#     dist_dd[app2] = dist\n",
    "\n",
    "# sort_dist = sorted(dist_dd.items(), key=operator.itemgetter(1))\n",
    "# print sort_dist[-1]\n",
    "\n",
    "\n",
    "\n",
    "# app1_metric = app2metric_dd['cudasdk_fastWalshTransform']\n",
    "\n",
    "# dist_dd = {}\n",
    "# for app2 in ['cudasdk_MCEstimatePiInlineP', 'rodinia_gaussian', 'cudasdk_MCEstimatePiP']:\n",
    "#     app2_metric = app2metric_dd[app2]\n",
    "#     dist = np.linalg.norm(app1_metric - app2_metric)\n",
    "#     dist_dd[app2] = dist\n",
    "\n",
    "# sort_dist = sorted(dist_dd.items(), key=operator.itemgetter(1))\n",
    "# print sort_dist[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top3 least impact (slowdown) for poly_correlation\n",
      "\n",
      "('cudasdk_MCEstimatePiInlineP', 0.0)\n",
      "('cudasdk_concurrentKernels', 0.0)\n",
      "('cudasdk_MCEstimatePiP', 0.0)\n",
      "\n",
      "Top3 least impact (slowdown) for poly_covariance\n",
      "\n",
      "('cudasdk_interval', -1.6653345369377348e-16)\n",
      "('cudasdk_MCEstimatePiInlineP', 0.0)\n",
      "('cudasdk_concurrentKernels', 0.0)\n"
     ]
    }
   ],
   "source": [
    "test2 = ['poly_correlation','poly_covariance']\n",
    "\n",
    "for app in test2:\n",
    "    select_top3_least_slowdown(app2trace_dd[app],app,app2trace_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top3 least impact (slowdown) for cudasdk_stereoDisparity\n",
      "\n",
      "('cudasdk_MCEstimatePiInlineP', 0.0)\n",
      "('cudasdk_MCEstimatePiP', 0.0)\n",
      "('cudasdk_interval', 0.013468186886816724)\n",
      "\n",
      "Top3 least impact (slowdown) for poly_3mm\n",
      "\n",
      "('cudasdk_MCEstimatePiInlineP', 0.0)\n",
      "('cudasdk_concurrentKernels', 0.0)\n",
      "('cudasdk_MCEstimatePiP', 0.0)\n"
     ]
    }
   ],
   "source": [
    "test3 = ['cudasdk_stereoDisparity','poly_3mm']\n",
    "\n",
    "for app in test3:\n",
    "    select_top3_least_slowdown(app2trace_dd[app],app,app2trace_dd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
